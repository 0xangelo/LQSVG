{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ebf8dc-cfe5-4cca-8798-b8587eabf64c",
   "metadata": {},
   "source": [
    "# True SVG Policy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f55ff-e854-4499-82e7-6f7fe2802931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import lqsvg.torch.named as nt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lqsvg.envs import lqr\n",
    "from lqsvg.envs.lqr.gym import LQGGenerator\n",
    "from lqsvg.policy.modules import TVLinearFeedback\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50e667-7d82-4871-adc5-88c6d1b5e5a3",
   "metadata": {},
   "source": [
    "### Environment generation\n",
    "\n",
    "In what follows we consider **time-invaryant dynamics**: $\\mathbf{F}_t, \\mathbf{f}_t, \\mathbf{\\Sigma}_t = \\mathbf{F}, \\mathbf{f}, \\mathbf{\\Sigma}, \\forall t\\in\\mathcal{T}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4326b1-a22b-4f94-b959-d2b8151fe8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = LQGGenerator(\n",
    "    n_state=2,\n",
    "    n_ctrl=2,\n",
    "    horizon=10,\n",
    "    seed=123,\n",
    "    stationary=True,\n",
    "    passive_eigval_range=(0.5, 1.5),\n",
    "    controllable=True,\n",
    "    transition_bias=False,\n",
    "    rand_trans_cov=False,\n",
    "    rand_init_cov=False,\n",
    "    cost_linear=False,\n",
    "    cost_cross=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5133ca-0e91-4188-bf18-061aa22c9d12",
   "metadata": {},
   "source": [
    "## Quadratic State-value\n",
    "\n",
    "$$\n",
    "        V^\\mu(\\mathbf{s}, t) = {\\tfrac12} \\mathbf{s}^\\intercal\\mathbf{V}_t\\mathbf{s} + \\mathbf{v}_t^\\intercal\\mathbf{s} + v_t, \\quad t\\in\\mathcal{T}^+ \\,,\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b30e5-c084-43b2-8109-643b2eebccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueFn(nn.Module):\n",
    "    def __init__(self, quadratic: lqr.Quadratic, timestep: int = 0):\n",
    "        super().__init__()\n",
    "        V, v, c = (x.select(\"H\", timestep) for x in quadratic)\n",
    "        self.register_buffer(\"V\", V)\n",
    "        self.register_buffer(\"v\", nt.vector_to_matrix(v))\n",
    "        self.register_buffer(\"c\", nt.scalar_to_matrix(c))\n",
    "        assert len(self.V.shape) == len(self.v.shape) == len(self.c.shape) == 2, (\n",
    "            self.V.shape,\n",
    "            self.v.shape,\n",
    "            self.c.shape,\n",
    "        )\n",
    "\n",
    "    def symeig(self) -> (Tensor, Tensor):\n",
    "        return torch.symeig(nt.unnamed(self.V), eigenvectors=True)\n",
    "\n",
    "    def forward(self, state: Tensor):\n",
    "        \"\"\"Calculate optimal state-value.\n",
    "\n",
    "        May be used with batched states.\n",
    "        \"\"\"\n",
    "        s = nt.vector_to_matrix(state)\n",
    "        value = nt.transpose(s) @ self.V @ s / 2 + nt.transpose(self.v) @ s + self.c\n",
    "        return nt.matrix_to_scalar(value)\n",
    "\n",
    "    def min(self):\n",
    "        Vinv = nt.unnamed(self.V).inverse()\n",
    "        return nt.matrix_to_vector(-Vinv @ self.v)\n",
    "\n",
    "    def expected(self, init: lqr.GaussInit):\n",
    "        \"\"\"Expected cost given mean and covariance matrix of the initial state.\n",
    "\n",
    "        https://en.wikipedia.org/wiki/Quadratic_form_(statistics)#Expectation.\n",
    "        \"\"\"\n",
    "        mean = nt.vector_to_matrix(init.mu)\n",
    "        cov = init.sig\n",
    "        value = (\n",
    "            nt.scalar_to_matrix(nt.trace(cov @ self.V)) / 2\n",
    "            + nt.transpose(mean) @ self.V @ mean\n",
    "            + nt.transpose(self.v) @ mean\n",
    "            + self.c\n",
    "        )\n",
    "        return nt.matrix_to_scalar(value)\n",
    "\n",
    "    def plot_3d(self, ax, mean: Optional[Tensor] = None, amp: float = 10):\n",
    "        if mean is None:\n",
    "            mean = self.min().detach().numpy()\n",
    "        else:\n",
    "            mean = mean.detach().numpy()\n",
    "\n",
    "        xrange = np.linspace(mean[0] - amp, mean[0] + amp, num=100)\n",
    "        yrange = np.linspace(mean[1] - amp, mean[1] + amp, num=100)\n",
    "        xbatch, ybatch = np.meshgrid(xrange, yrange)\n",
    "        assert xbatch.shape == ybatch.shape == (100, 100)\n",
    "\n",
    "        init_states = np.stack([xbatch, ybatch], axis=-1).reshape((-1, 2))\n",
    "        init_states = torch.from_numpy(init_states).float().refine_names(\"B\", \"R\")\n",
    "        assert init_states.shape == (10000, 2), init_states.shape\n",
    "\n",
    "        init_values = self(init_states).detach().numpy()\n",
    "        assert init_values.shape == (10000,), init_values.shape\n",
    "\n",
    "        init_values = init_values.reshape(xbatch.shape)\n",
    "        ax.plot_surface(xbatch, ybatch, init_values, cmap=cm.coolwarm)\n",
    "\n",
    "        ax.set_xlabel(\"x1\")\n",
    "        ax.set_ylabel(\"x2\")\n",
    "        ax.set_zlabel(\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4021fdd-0090-496b-a470-39aa7054632e",
   "metadata": {},
   "source": [
    "# Exact methods\n",
    "---\n",
    "## LQG control\n",
    "\n",
    "<img src=\"images/LQG - Control.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe8588-f9e3-4284-96c8-d430ed2be33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_solution(policy, qval, vval):\n",
    "    K, k = policy\n",
    "    Q, q, qc = qval\n",
    "    V, v, vc = vval\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    Policy:\n",
    "        K: {K.shape}, {K.names}\n",
    "        k: {k.shape}, {k.names}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    Q-value:\n",
    "        Q: {Q.shape}, {Q.names}\n",
    "        q: {q.shape}, {q.names}\n",
    "        const: {qc.shape}, {qc.names}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    V-value:\n",
    "        V: {V.shape}, {V.names}\n",
    "        V: {v.shape}, {v.names}\n",
    "        const: {vc.shape}, {vc.names}\n",
    "    \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9be235-5bf8-4c80-ae46-ed58a8e294a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.n_state = 2\n",
    "generator.n_ctrl = 2\n",
    "dynamics, cost, init = generator(n_batch=None)\n",
    "lqg_control = lqr.NamedLQGControl(\n",
    "    generator.n_state, generator.n_ctrl, generator.horizon\n",
    ")\n",
    "pistar, qstar, vstar = lqg_control(dynamics, cost)\n",
    "print_solution(pistar, qstar, vstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6687d7-9489-47b7-9d9c-5e80b7e51519",
   "metadata": {},
   "outputs": [],
   "source": [
    "vstar_fn = ValueFn(vstar)\n",
    "print(vstar_fn.V)\n",
    "print(vstar_fn.v)\n",
    "print(vstar_fn.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2436d3-998d-4d59-ba3d-5f5dac2abe1f",
   "metadata": {},
   "source": [
    "### Optimal value for best initial state\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{s}_{min} \n",
    "&= \\arg\\min_{\\mathbf{s}} V^\\star(\\mathbf{s}, 0) \\\\\n",
    "&= \\arg\\min_{\\mathbf{s}} \\mathbf{s}^\\intercal \\mathbf{V}_0^\\star \\mathbf{s} + {\\mathbf{v}_0^\\star}^\\intercal \\mathbf{s} + v_0^\\star \\\\\n",
    "&= -{\\mathbf{V}_0^\\star}^{-1} \\mathbf{v}_0^\\star \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33eead-a4e7-4753-a4d1-aec191261209",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum = vstar_fn.min()\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Best initial state: {minimum}\n",
    "    Best initial value: {vstar_fn(minimum)}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2041ff-684d-4c12-b006-05627e42ff8d",
   "metadata": {},
   "source": [
    "### Optimal expected initial state value\n",
    "$$\n",
    "\\mathbb{E}_{\\mathbf{s}\\sim\\rho} \\left[ V^{\\star}(\\mathbf{s}, 0) \\right]\n",
    "= \\text{Tr}(\\mathbf{V}_0\\mathbf{\\Sigma}_0) + \\mathbf{\\mu}_0^\\intercal \\mathbf{V}_0 \\mathbf{\\mu}_0 + \\mathbf{v}_0^\\intercal \\mathbf{\\mu}_0 + v_0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e58e9-d4ef-41ef-bdc1-fd44a706eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"\"\"\n",
    "    Mean: {init.mu}\n",
    "    Covariance: {init.sig}\n",
    "    Expected value: {vstar_fn.expected(init)}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec2f21e-7765-4148-abe7-eea2d910fae5",
   "metadata": {},
   "source": [
    "### Optimal value for each initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad54bb6-6a17-46a1-b280-350a1692b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[2 * 6.4, 2 * 4.8])\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "vstar_fn.plot_3d(ax, mean=init.mu)\n",
    "# plt.savefig(\"navigation2d_value.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619074e1-4236-4551-a4e0-055426c1f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vstar_fn.symeig())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5209a25d-c825-447c-a268-fe3d361a4e0a",
   "metadata": {},
   "source": [
    "## LQG prediction (Policy Evaluation)\n",
    "\n",
    "<img src=\"images/LQG - Prediction.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6f8b1-27d1-4b74-b207-88c59589fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "lqg_prediction = lqr.NamedLQGPrediction(\n",
    "    generator.n_state, generator.n_ctrl, generator.horizon\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4dbd88-e43d-4ba2-bd4a-2f9a72526230",
   "metadata": {},
   "source": [
    "## Time-varying linear policy\n",
    "\n",
    "A time-varying linear policy is a mapping $\\mu_\\theta: \\mathcal{S}\\times\\mathcal{T} \\mapsto \\mathcal{A}$ such that\n",
    "$$\n",
    "    \\mu_\\theta(\\mathbf{s}, t) = \\mathbf{K}_t \\mathbf{s} + \\mathbf{k}_t\n",
    "    \\,,\n",
    "$$\n",
    "where $\\mathbf{K}_t \\in \\mathbb{R}^{d\\times n}$, $\\mathbf{k}_t \\in \\mathbb{R}^d$ and $\\theta = \\{\\mathbf{K}_t, \\mathbf{k}_t\\}_{t\\in\\mathcal{T}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46644d-d8a5-4345-885a-f79b33d67354",
   "metadata": {},
   "source": [
    "## Perturbed optimal policies\n",
    "\n",
    "We generate sub-optimal policies by adding uniform noise to the optimal policy's parameters, i.e., \n",
    "$$\n",
    "    \\mathbf{K}_t = \\mathbf{K}_t^\\star + \\epsilon, \\qquad \\epsilon \\sim \\mathcal{U}(\\mathbf{0}, \\mathbf{0.5}) \\\\\n",
    "    \\mathbf{k}_t = \\mathbf{k}_t^\\star + \\epsilon, \\qquad \\epsilon \\sim \\mathcal{U}(\\mathbf{0}, \\mathbf{0.5})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e6307-beb6-4e5b-a8a2-7db5648145da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_policy(policy, rng):\n",
    "    Knames, knames = map(lambda x: x.names, policy)\n",
    "    K, k = map(lambda x: x.numpy(), policy)\n",
    "    K = torch.from_numpy(K + rng.standard_normal(size=K.shape, dtype=K.dtype) * 0.5)\n",
    "    k = torch.from_numpy(k + rng.standard_normal(size=k.shape, dtype=k.dtype) * 0.5)\n",
    "    return (K.refine_names(*Knames), k.refine_names(*knames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560fc975-a101-461f-b845-e97b9a23db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = rand_policy(pistar, rng=generator._rng)\n",
    "\n",
    "_, vval = lqg_prediction(policy, dynamics, cost)\n",
    "vval_fn = ValueFn(vval)\n",
    "min_state = vval_fn.min()\n",
    "print(\n",
    "    f\"\"\"\n",
    "    V: {vval_fn.V}\n",
    "    v: {vval_fn.v}\n",
    "    c: {vval_fn.c}\n",
    "    \n",
    "    min state: {min_state}\n",
    "    min value: {vval_fn(min_state)}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58770125-ce9f-4646-b228-d6f070b885ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[2 * 6.4, 4 * 4.8])\n",
    "ax = fig.add_subplot(1, 2, 1, projection=\"3d\")\n",
    "vval_fn.plot_3d(ax, mean=init.mu)\n",
    "ax.set_title(\"Perturbed\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection=\"3d\")\n",
    "vstar_fn.plot_3d(ax, mean=init.mu)\n",
    "ax.set_title(\"Optimal\")\n",
    "\n",
    "# plt.savefig(\"navigation2d_value.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f57442-6000-42d3-b696-0e5c6574bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Perturbed:\")\n",
    "print(vval_fn.symeig())\n",
    "print(\"Optimal:\")\n",
    "print(vstar_fn.symeig())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e15dfa8-d9e8-4f9a-b2a3-52722388ed22",
   "metadata": {},
   "source": [
    "## Policy learning via true value gradients\n",
    "\n",
    "LQG prediction can be seen as a function mapping policy parameters (with the dynamics kept constant) to value function coefficients:\n",
    "$$\n",
    "\\left( \\mathbf{Q}, \\mathbf{q}, q, \\mathbf{V}, \\mathbf{v}, v \\right) = \\text{LQGPrediction}(\\theta)\n",
    "$$\n",
    "\n",
    "Thus, we can write each coeficient as a function of policy parameters. For example, the value function for a policy $\\mu_\\theta$ would be:\n",
    "$$\n",
    "V^\\mu(\\mathbf{s}, t) = \\tfrac12 \\mathbf{s}^\\intercal \\mathbf{V}_t(\\theta) \\mathbf{s} + \\mathbf{v}_t(\\theta)^\\intercal \\mathbf{s} + v_t(\\theta)\n",
    "$$\n",
    "\n",
    "We can then express policy performance as a direct function of policy parameters:\n",
    "$$\n",
    "\\begin{align}\n",
    "J(\\theta) \n",
    "    &= \\mathbb{E}_{\\mathbf{s}\\sim\\rho} \\left[ \\tfrac12 \\mathbf{s}^\\intercal \\mathbf{V}_0(\\theta) \\mathbf{s} + \\mathbf{v}_0(\\theta)^\\intercal \\mathbf{s} + v_0(\\theta) \\right] \\\\\n",
    "    &= \\text{Tr}(\\mathbf{V}_0(\\theta)\\mathbf{\\Sigma}_0) + \\mathbf{\\mu}_0^\\intercal \\mathbf{V}_0(\\theta) \\mathbf{\\mu}_0 + \\mathbf{v}_0(\\theta)^\\intercal \\mathbf{\\mu}_0 + v_0(\\theta)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c57337b-110d-429f-9251-f66f16d2f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVLFLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dynamics: lqr.LinDynamics,\n",
    "        cost: lqr.QuadCost,\n",
    "        init: lqr.GaussInit,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        n_state = dynamics.F.size(\"R\")\n",
    "        n_ctrl = dynamics.F.size(\"C\") - n_state\n",
    "        horizon = dynamics.F.size(\"H\")\n",
    "        self.predict = lqr.NamedLQGPrediction(n_state, n_ctrl, horizon)\n",
    "        self.dynamics = dynamics\n",
    "        self.cost = cost\n",
    "        self.init = init\n",
    "\n",
    "    def forward(self, policy: lqr.Linear):\n",
    "        _, vval = self.predict(policy, self.dynamics, self.cost)\n",
    "        vval_fn = ValueFn(vval)\n",
    "        cost = vval_fn.expected(self.init)\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91806520-9d11-4297-898c-dfdbb189421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = TVLFLoss(dynamics, cost, init)\n",
    "loss = loss_fn(policy)\n",
    "print(\"Random policy loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc41f99b-7a42-405e-baa1-12e33886da99",
   "metadata": {},
   "source": [
    "Finally, since the value function coefficients are differentiable functions of the policy parameters, we can optimize the latter for better performance via gradient ascent\n",
    "$$\n",
    "\\theta \\gets \\theta + \\alpha \\nabla_{\\theta} J(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdfd026-89fa-4fb1-b47e-10d8e367f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvlp = TVLinearFeedback.from_existing(policy)\n",
    "optim = torch.optim.Adam(tvlp.parameters(), lr=1e-3)\n",
    "\n",
    "for i in range(1000):\n",
    "    # for i in range(1):\n",
    "    for p in tvlp.parameters():\n",
    "        p.grad = None\n",
    "    loss = loss_fn(tvlp.gains())\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if i % 100 == 0:\n",
    "        print(\"Loss:\", loss.item())\n",
    "print(\"Loss:\", loss_fn(tvlp.gains()).item())\n",
    "print(\"Best possible:\", vstar_fn.expected(loss_fn.init).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb27612-1cb4-4d5d-8a8b-93acadb65e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_vval = ValueFn(lqg_prediction(tvlp.gains(), dynamics, cost)[1])\n",
    "fig = plt.figure(figsize=[2 * 6.4, 4 * 4.8])\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1, projection=\"3d\")\n",
    "vstar_fn.plot_3d(ax, mean=init.mu)\n",
    "ax.set_title(\"Optimal\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection=\"3d\")\n",
    "learned_vval.plot_3d(ax, mean=init.mu)\n",
    "ax.set_title(\"Learned\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "compact-batman",
   "metadata": {},
   "source": [
    "# Value gradient error for linear policies in LQG\n",
    "\n",
    "Experiment description on [Overleaf](https://www.overleaf.com/read/cmbgmxxpxqzr).\n",
    "\n",
    "**Versioning:** [CalVer](https://calver.org) `MM.DD.MICRO`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-notice",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import lqsvg\n",
    "import lqsvg.envs.lqr.utils as lqg_util\n",
    "import lqsvg.experiment.utils as utils\n",
    "import lqsvg.torch.named as nt\n",
    "import pytorch_lightning as pl\n",
    "import ray\n",
    "from lqsvg.experiment.data import build_datamodule\n",
    "from lqsvg.experiment.models import LightningModel, RecurrentModel\n",
    "from lqsvg.experiment.worker import make_worker\n",
    "from ray import tune\n",
    "from raylab.policy.model_based.lightning import LightningTrainerSpec\n",
    "from torch import Tensor\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStatistics(pl.callbacks.Callback):\n",
    "    def on_train_batch_end(\n",
    "        self,\n",
    "        trainer: pl.Trainer,\n",
    "        pl_module: pl.LightningModule,\n",
    "        outputs: Tensor,\n",
    "        batch: tuple[Tensor, Tensor, Tensor],\n",
    "        batch_idx: int,\n",
    "        dataloader_idx: int,\n",
    "    ):\n",
    "        del trainer, outputs, batch_idx, dataloader_idx\n",
    "        obs, act, new_obs = batch\n",
    "        pl_module.log(\"train/obs-mean\", obs.mean())\n",
    "        pl_module.log(\"train/obs-std\", obs.std())\n",
    "        pl_module.log(\"train/act-mean\", act.mean())\n",
    "        pl_module.log(\"train/act-std\", act.std())\n",
    "        pl_module.log(\"train/new_obs-mean\", new_obs.mean())\n",
    "        pl_module.log(\"train/new_obs-std\", new_obs.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(tune.Trainable):\n",
    "    def setup(self, config: dict):\n",
    "        os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "        cwd = config.pop(\"wandb_dir\")\n",
    "        tags = config.pop(\"wandb_tags\", [])\n",
    "        self.run = wandb.init(\n",
    "            dir=cwd,\n",
    "            name=\"SVG Prediction\",\n",
    "            config=config,\n",
    "            project=\"LQG-SVG\",\n",
    "            entity=\"angelovtt\",\n",
    "            tags=[utils.calver()] + tags,\n",
    "            reinit=True,\n",
    "            mode=\"online\",\n",
    "            save_code=True,\n",
    "        )\n",
    "\n",
    "        self.make_worker()\n",
    "        self.make_model()\n",
    "        self.make_datamodule()\n",
    "        self.make_lightning_trainer()\n",
    "        #         self.make_artifact()\n",
    "        utils.suppress_lightning_info_logging()\n",
    "\n",
    "    @property\n",
    "    def hparams(self):\n",
    "        return self.run.config\n",
    "\n",
    "    def make_worker(self):\n",
    "        with nt.suppress_named_tensor_warning():\n",
    "            self.worker = make_worker(\n",
    "                env_config=self.hparams.env_config,\n",
    "                # TorchPolicy internally pulls the 'policy' key from config\n",
    "                policy_config=dict(self.hparams),\n",
    "                log_level=logging.WARNING,\n",
    "            )\n",
    "\n",
    "    def make_model(self):\n",
    "        cls = RecurrentModel if self.hparams.recurrent_training else LightningModel\n",
    "        self.model = cls(self.worker.get_policy(), self.worker.env)\n",
    "        self.model.hparams.learning_rate = self.hparams.learning_rate\n",
    "        self.model.hparams.mc_samples = self.hparams.mc_samples\n",
    "        self.model.hparams.weight_decay = self.hparams.weight_decay\n",
    "        self.model.hparams.empvar_samples = self.hparams.empvar_samples\n",
    "\n",
    "    def make_datamodule(self):\n",
    "        self.datamodule = build_datamodule(\n",
    "            self.worker, total_trajs=self.hparams.total_trajs\n",
    "        )\n",
    "        self.datamodule.collect_trajectories(prog=False)\n",
    "\n",
    "    def make_lightning_trainer(self):\n",
    "        logger = pl.loggers.WandbLogger(\n",
    "            save_dir=self.run.dir, log_model=False, experiment=self.run\n",
    "        )\n",
    "\n",
    "        early_stopping = pl.callbacks.EarlyStopping(\n",
    "            monitor=LightningModel.early_stop_on,\n",
    "            min_delta=float(self.hparams.improvement_delta),\n",
    "            patience=int(self.hparams.patience),\n",
    "            mode=\"min\",\n",
    "            strict=True,\n",
    "        )\n",
    "        #         checkpointing = pl.callbacks.ModelCheckpoint(\n",
    "        #             dirpath=osp.join(self.run.dir, \"checkpoints\"),\n",
    "        #             monitor=LightningModel.early_stop_on,\n",
    "        #             save_top_k=-1,\n",
    "        #             period=10,\n",
    "        #             save_last=True,\n",
    "        #         )\n",
    "        self.trainer = pl.Trainer(\n",
    "            default_root_dir=self.run.dir,\n",
    "            logger=logger,\n",
    "            num_sanity_val_steps=2,\n",
    "            #             callbacks=[early_stopping, checkpointing, InputStatistics()],\n",
    "            callbacks=[early_stopping, InputStatistics()],\n",
    "            max_epochs=self.hparams.max_epochs,\n",
    "            progress_bar_refresh_rate=0,  # don't show progress bar for model training\n",
    "            weights_summary=None,  # don't print summary before training\n",
    "        )\n",
    "\n",
    "    def make_artifact(self):\n",
    "        env = self.worker.env\n",
    "        self.artifact = wandb.Artifact(\n",
    "            f\"svg_prediction-lqg{env.n_state}.{env.n_ctrl}.{env.horizon}\", type=\"model\"\n",
    "        )\n",
    "\n",
    "    def step(self) -> dict:\n",
    "        self.log_env_info()\n",
    "        with utils.suppress_dataloader_warning():\n",
    "            self.trainer.fit(self.model, datamodule=self.datamodule)\n",
    "\n",
    "            results = self.trainer.test(self.model, datamodule=self.datamodule)[0]\n",
    "            self.run.summary.update(results)\n",
    "\n",
    "        #         try:\n",
    "        #             self.artifact.add_dir(self.trainer.checkpoint_callback.dirpath)\n",
    "        #             self.run.log_artifact(self.artifact)\n",
    "        #         except ValueError:\n",
    "        #             # Sometimes add_dir fails with 'not a directory name'. Shall investigate\n",
    "        #             pass\n",
    "        return {tune.result.DONE: True, **results}\n",
    "\n",
    "    def log_env_info(self):\n",
    "        dynamics = self.worker.env.dynamics\n",
    "        eigvals = lqg_util.stationary_eigvals(dynamics)\n",
    "        tests = {\n",
    "            \"stability\": lqg_util.isstable(eigvals=eigvals),\n",
    "            \"controllability\": lqg_util.iscontrollable(dynamics),\n",
    "        }\n",
    "        self.run.summary.update(tests)\n",
    "        self.run.summary.update({\"Fs_eigvals\": wandb.Histogram(eigvals)})\n",
    "\n",
    "    def cleanup(self):\n",
    "        self.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-elimination",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.init(logging_level=logging.WARNING)\n",
    "lqsvg.register_all()\n",
    "utils.suppress_lightning_info_logging()\n",
    "\n",
    "config = {\n",
    "    \"wandb_dir\": os.getcwd(),\n",
    "    \"wandb_tags\": \"easy test_recurrent\".split(),\n",
    "    \"env_config\": dict(\n",
    "        n_state=tune.randint(2, 11),\n",
    "        n_ctrl=tune.randint(2, 11),\n",
    "        horizon=tune.randint(1, 200),\n",
    "        stationary=True,\n",
    "        Fs_eigval_range=(0.0, 1.0),\n",
    "        transition_bias=False,\n",
    "        rand_trans_cov=False,\n",
    "        rand_init_cov=False,\n",
    "        cost_linear=False,\n",
    "        cost_cross=False,\n",
    "        num_envs=100,\n",
    "    ),\n",
    "    \"policy\": {\n",
    "        \"module\": {\n",
    "            \"policy_initializer\": \"xavier_uniform\",\n",
    "            \"model_initializer\": \"xavier_uniform\",\n",
    "            \"stationary_model\": True,\n",
    "            \"residual_model\": True,\n",
    "            \"model_input_norm\": None,\n",
    "        }\n",
    "    },\n",
    "    \"recurrent_training\": tune.choice([True, False]),\n",
    "    \"learning_rate\": tune.loguniform(3e-4, 1e-2),\n",
    "    \"weight_decay\": tune.loguniform(1e-5, 1e-3),\n",
    "    \"mc_samples\": 32,\n",
    "    \"empvar_samples\": 10,\n",
    "    \"total_trajs\": 1000,\n",
    "    \"improvement_delta\": 0.0,\n",
    "    \"patience\": 3,\n",
    "    \"max_epochs\": 1000,\n",
    "}\n",
    "\n",
    "analysis = tune.run(Experiment, config=config, num_samples=128, local_dir=\"./results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

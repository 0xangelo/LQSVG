{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Closer Look at Model-Based Policy Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Linear Quadratic Gaussian (LQG) Problems\n",
    "In what follows we consider MDPs with:\n",
    "1. continuous state space $\\mathbf{s} \\in \\mathcal{S} = \\mathbb{R}^n$\n",
    "2. continuous action space $\\mathbf{a} \\in \\mathcal{A} = \\mathbb{R}^d$\n",
    "3. finite time horizon $N \\in \\mathbb{N}$ and timesteps $t \\in \\mathcal{T} = \\{0, \\dots, N - 1\\}$\n",
    "4. time-varying linear Gaussian dynamics \n",
    "    $$\n",
    "    \\mathbf{s}_{t+1} \\sim p(\\cdot| \\mathbf{s}_t, \\mathbf{a}_t) = \\mathcal{N}\\left( \\cdot ~\\middle|~ \\mathbf{F}_t \\begin{bmatrix}\\mathbf{s}_t \\\\ \\mathbf{a}_t\\end{bmatrix} + \\mathbf{f}_t, \\mathbf{\\Sigma}_{t} \\right)\n",
    "    $$\n",
    "5. time-varying quadratic costs \n",
    "    $$\n",
    "    r_{t+1} = R(\\mathbf{s}_t, \\mathbf{a}_t) = - \\tfrac{1}{2} \\begin{bmatrix}\\mathbf{s}_t \\\\ \\mathbf{a}_t\\end{bmatrix}^\\intercal \\mathbf{C}_t \\begin{bmatrix}\\mathbf{s}_t \\\\ \\mathbf{a}_t\\end{bmatrix} - \\mathbf{c}_t^\\intercal \\begin{bmatrix}\\mathbf{s}_t \\\\ \\mathbf{a}_t\\end{bmatrix}\n",
    "    $$\n",
    "6. Gaussian-distributed initial state \n",
    "    $$\n",
    "    \\mathbf{s}_0 \\sim \\rho = \\mathcal{N}(\\mathbf{\\mu}_\\rho, \\mathbf{\\Sigma}_\\rho)\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Optional\n",
    "\n",
    "import lqsvg.envs.lqr.utils as utils\n",
    "import lqsvg.torch.named as nt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from gym.spaces import Box\n",
    "from lqsvg.envs import lqr\n",
    "from lqsvg.envs.lqr.gym import LQGGenerator\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import FormatStrFormatter, MaxNLocator\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import ortho_group\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment generation\n",
    "\n",
    "In what follows we consider **time-invaryant dynamics**: $\\mathbf{F}_t, \\mathbf{f}_t, \\mathbf{\\Sigma}_t = \\mathbf{F}, \\mathbf{f}, \\mathbf{\\Sigma}, \\forall t\\in\\mathcal{T}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = LQGGenerator(\n",
    "    n_state=2,\n",
    "    n_ctrl=2,\n",
    "    horizon=20,\n",
    "    seed=123,\n",
    "    stationary=True,\n",
    "    passive_eigval_range=(0.0, 1.0),\n",
    "    controllable=False,\n",
    "    transition_bias=False,\n",
    "    rand_trans_cov=False,\n",
    "    rand_init_cov=False,\n",
    "    cost_linear=False,\n",
    "    cost_cross=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nt.suppress_named_tensor_warning():\n",
    "    dynamics, cost, init = generator(n_batch=None)\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "Dynamics:\n",
    "    F: {dynamics.F.shape}, {dynamics.F.names}\n",
    "    f: {dynamics.f.shape}, {dynamics.f.names}\n",
    "    W: {dynamics.W.shape}, {dynamics.W.names}\n",
    "\n",
    "Cost:\n",
    "    C: {cost.C.shape}, {cost.C.names}\n",
    "    c: {cost.c.shape}, {cost.c.names}\n",
    "    \n",
    "Initial state:\n",
    "    mean: {init.mu.shape}, {init.mu.names}\n",
    "    covariance: {init.sig.shape}, {init.sig.names}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sys_eigvals(dynamics: lqr.LinSDynamics) -> np.ndarray:\n",
    "    eigvals = utils.stationary_eigvals(dynamics)\n",
    "    return eigvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_eigvals(dynamics: lqr.LinSDynamics) -> np.ndarray:\n",
    "    return np.abs(sys_eigvals(dynamics)).reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def min_eigval_distance(dynamics: lqr.LinSDynamics) -> np.ndarray:\n",
    "#     eigvals = sys_eigvals(dynamics)[..., :, np.newaxis]\n",
    "#     eigvals_T = eigvals.swapaxes(-2, -1)\n",
    "#     abs_diff = np.abs(eigvals - eigvals_T)\n",
    "#     return np.min(abs_diff, axis=(-2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_abs_eigval(dynamics: lqr.LinSDynamics) -> np.ndarray:\n",
    "    return np.abs(sys_eigvals(dynamics)).max(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_real_eigval(dynamics: lqr.LinSDynamics) -> np.ndarray:\n",
    "    eigval = utils.stationary_eigvals(dynamics)\n",
    "    return np.all(np.isreal(eigval), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_defficient(dynamics: lqr.LinSDynamics) -> np.ndarray:\n",
    "    n_state, _, _ = lqr.dims_from_dynamics(dynamics)\n",
    "    A, _ = utils.stationary_dynamics_factors(dynamics)\n",
    "    return np.linalg.matrix_rank(A.numpy()) < n_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issymmetric(dynamics: lqr.LinSDynamics) -> np.ndarray:\n",
    "    A, _ = utils.stationary_dynamics_factors(dynamics)\n",
    "    return np.all(torch.abs(A - nt.transpose(A)).numpy() < 1e-8, axis=(-2, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability of the un-actuated system\n",
    "\n",
    "Suppose we run the system with 0 inputs for an indefinite amount of time. Will the values of $\\mathbf{s}_t$ diverge? We test for this by checking that the eigenvalues $\\{\\lambda_i \\}_{i=1}^{n}$ of $\\mathbf{F_s}$, where $\\mathbf{F} = [\\mathbf{F_s\\ F_a}]$, are all within the unit circle in the complex plane.\n",
    "\n",
    "![](images/stable_eigvals.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.isstable(dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we spot any trends when generating transition dynamics by sampling the entries in $\\mathbf{F}$ independently from a standard Normal distribution. ($\\mathcal{N}(0, 1)$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_normal_dynamics(gen: LQGGenerator, samples: int) -> lqr.LinSDynamics:\n",
    "    dynamics = gen.make_dynamics(n_batch=samples)\n",
    "    A, B = utils.stationary_dynamics_factors(dynamics)\n",
    "    F = torch.cat([torch.randn_like(A), B], dim=-1).expand_as(dynamics.F)\n",
    "    F = nt.horizon(F)\n",
    "    return lqr.LinSDynamics(F=F, f=dynamics.f, W=dynamics.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable = utils.isstable(standard_normal_dynamics(generator, 10))\n",
    "print(stable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a lot of the dynamics generated are unstable. Let's plot a histogram of stable vs. unstable systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=utils.isstable(standard_normal_dynamics(generator, 500)).astype(str))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We quickly see that a majority of systems generated this way are unstable. We may then see how unstable by plotting a histogram of the magnitude of the largest eigenvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=abs_eigvals(standard_normal_dynamics(generator, 1000)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=max_abs_eigval(standard_normal_dynamics(generator, 1000)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a lot of the generated matrices have eigenvalues with norms well above 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also check if the trends observed above generalize to different state sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_by_state_dim(func: callable, sampler: callable, **kwargs):\n",
    "    n_samples = 1000\n",
    "    scale = 1.5\n",
    "    fig, ax = plt.subplots(1, figsize=[scale * 6.4, scale * 4.8])\n",
    "    x = \"State size\"\n",
    "    y = func.__name__.replace(\"_\", \" \").capitalize()\n",
    "    kwargs.update(discrete=(True, False))\n",
    "\n",
    "    dfs = []\n",
    "    state_sizes = [2 + i for i in range(19)]\n",
    "    for state_size in tqdm(state_sizes):\n",
    "        with generator.config(n_state=state_size):\n",
    "            samples = func(sampler(generator, n_samples))\n",
    "            if samples.dtype == bool:\n",
    "                samples = samples.astype(str)\n",
    "                kwargs.update(stat=\"probability\", discrete=(True, True))\n",
    "\n",
    "            state_dim = np.full_like(samples, fill_value=generator.n_state, dtype=int)\n",
    "            dfs += [pd.DataFrame({y: samples, x: state_dim})]\n",
    "\n",
    "    sns.histplot(ax=ax, x=x, y=y, data=pd.concat(dfs), cbar=True, **kwargs)\n",
    "\n",
    "    fig.suptitle(sampler.__name__.replace(\"_\", \" \").capitalize())\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(state_sizes)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_by_state_dim(rank_defficient, standard_normal_dynamics)\n",
    "\n",
    "hist_by_state_dim(abs_eigvals, standard_normal_dynamics)\n",
    "\n",
    "hist_by_state_dim(max_abs_eigval, standard_normal_dynamics)\n",
    "\n",
    "hist_by_state_dim(all_real_eigval, standard_normal_dynamics)\n",
    "\n",
    "hist_by_state_dim(utils.isstable, standard_normal_dynamics)\n",
    "\n",
    "hist_by_state_dim(utils.iscontrollable, standard_normal_dynamics)\n",
    "\n",
    "hist_by_state_dim(utils.is_pbh_ctrb, standard_normal_dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating stable dynamics\n",
    "\n",
    "To have stable dynamics we generate random matrices $\\mathbf{F_s}$ with eigenvalues with absolute values less or equal to 1. We start by sampling each eigenvalue independently from the uniform distribution $\\mathcal{U}(-1, 1)$. Then we use the trick described in the blog post [Generate a random matrix with specified eigenvalues](https://blogs.sas.com/content/iml/2012/03/30/geneate-a-random-matrix-with-specified-eigenvalues.html) to generate a random matrix with the sampled eigenvalues.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> for now we sample only real eigenvalues\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_dynamics(gen: LQGGenerator, samples: int) -> lqr.LinSDynamics:\n",
    "    with gen.config(passive_eigval_range=(0., 1.)):\n",
    "        return gen.make_dynamics(n_batch=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_by_state_dim(rank_defficient, stable_dynamics)\n",
    "\n",
    "hist_by_state_dim(utils.isstable, stable_dynamics)\n",
    "\n",
    "hist_by_state_dim(max_abs_eigval, stable_dynamics)\n",
    "\n",
    "hist_by_state_dim(abs_eigvals, stable_dynamics)\n",
    "\n",
    "hist_by_state_dim(all_real_eigval, stable_dynamics)\n",
    "\n",
    "hist_by_state_dim(issymmetric, stable_dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing controllability\n",
    "\n",
    "Next, we build the **controllability matrix** for randomly generated systems and visualize the distribution of the controllability status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_by_state_dim(utils.iscontrollable, standard_normal_dynamics)\n",
    "\n",
    "hist_by_state_dim(utils.iscontrollable, stable_dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for standard normal generators the resulting systems are mostly uncontrollable as the state size increases. On the other hand, the stable dynamics generated are mostly controllable.\n",
    "\n",
    "Let's try to generate stable, controllable systems by exploiting the consequences of the Popov-Belevitch-Hautus (PBH) test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_ctrb_dynamics(gen: LQGGenerator, samples: int) -> lqr.LinSDynamics:\n",
    "    with gen.config(passive_eigval_range=(0., 1.), controllable=True):\n",
    "        return gen.make_dynamics(n_batch=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstable_ctrb_dynamics(gen: LQGGenerator, samples: int) -> lqr.LinSDynamics:\n",
    "    with gen.config(passive_eigval_range=(.5, 1.5), controllable=True):\n",
    "        return gen.make_dynamics(n_batch=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_by_state_dim(utils.iscontrollable, unstable_ctrb_dynamics)\n",
    "\n",
    "hist_by_state_dim(utils.iscontrollable, stable_ctrb_dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epic fail :/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing Controllability via PBH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_by_state_dim(utils.is_pbh_ctrb, standard_normal_dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_by_state_dim(utils.is_pbh_ctrb, stable_dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_by_state_dim(utils.is_pbh_ctrb, stable_ctrb_dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Stabilizability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_by_state_dim(utils.isstabilizable, standard_normal_dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_by_state_dim(utils.isstabilizable, stable_dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_by_state_dim(utils.isstabilizable, stable_ctrb_dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-varying linear policy\n",
    "\n",
    "A time-varying linear policy is a mapping $\\mu_\\theta: \\mathcal{S}\\times\\mathcal{T} \\mapsto \\mathcal{A}$ such that\n",
    "$$\n",
    "    \\mu_\\theta(\\mathbf{s}, t) = \\mathbf{K}_t \\mathbf{s} + \\mathbf{k}_t\n",
    "    \\,,\n",
    "$$\n",
    "where $\\mathbf{K}_t \\in \\mathbb{R}^{d\\times n}$, $\\mathbf{k}_t \\in \\mathbb{R}^d$ and $\\theta = \\{\\mathbf{K}_t, \\mathbf{k}_t\\}_{t\\in\\mathcal{T}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lqsvg.policy.modules import TVLinearFeedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic State-value\n",
    "\n",
    "$$\n",
    "        V^\\mu(\\mathbf{s}, t) = {\\tfrac12} \\mathbf{s}^\\intercal\\mathbf{V}_t\\mathbf{s} + \\mathbf{v}_t^\\intercal\\mathbf{s} + v_t, \\quad t\\in\\mathcal{T}^+ \\,,\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueFn(nn.Module):\n",
    "    def __init__(self, quadratic: lqr.Quadratic, timestep: int = 0):\n",
    "        super().__init__()\n",
    "        V, v, c = (x.select(\"H\", timestep) for x in quadratic)\n",
    "        self.register_buffer(\"V\", V.align_to(\"R\", \"C\"))\n",
    "        self.register_buffer(\"v\", v.align_to(\"R\", \"C\"))\n",
    "        self.register_buffer(\"c\", c.align_to(\"R\", \"C\"))\n",
    "        assert len(self.V.shape) == len(self.v.shape) == len(self.c.shape) == 2, (\n",
    "            self.V.shape,\n",
    "            self.v.shape,\n",
    "            self.c.shape,\n",
    "        )\n",
    "\n",
    "    def symeig(self) -> Tensor:\n",
    "        return torch.symeig(self.V.rename(None), eigenvectors=True)\n",
    "\n",
    "    def forward(self, state: Tensor):\n",
    "        \"\"\"Calculate optimal state-value.\n",
    "\n",
    "        May be used with batched states.\n",
    "        \"\"\"\n",
    "        s = nt.vector_to_matrix(state)\n",
    "        value = nt.transpose(s) @ self.V @ s / 2 + nt.transpose(self.v) @ s + self.c\n",
    "        return nt.matrix_to_scalar(value)\n",
    "\n",
    "    def min(self):\n",
    "        Vinv = nt.unnamed(self.V).inverse()\n",
    "        return nt.matrix_to_vector(-Vinv @ self.v)\n",
    "\n",
    "    def expected(self, init: lqr.GaussInit):\n",
    "        \"\"\"Expected cost given mean and covariance matrix of the initial state.\n",
    "\n",
    "        https://en.wikipedia.org/wiki/Quadratic_form_(statistics)#Expectation.\n",
    "        \"\"\"\n",
    "        mean = nt.vector_to_matrix(init.mu)\n",
    "        cov = init.sig\n",
    "        value = (\n",
    "            nt.scalar_to_matrix(nt.trace(cov @ self.V)) / 2\n",
    "            + nt.transpose(mean) @ self.V @ mean\n",
    "            + nt.transpose(self.v) @ mean\n",
    "            + self.c\n",
    "        )\n",
    "        return nt.matrix_to_scalar(value)\n",
    "\n",
    "    def plot_3d(self, ax, mean: Optional[Tensor] = None, amp: float = 10):\n",
    "        if mean is None:\n",
    "            mean = self.min().detach().numpy()\n",
    "        else:\n",
    "            mean = mean.detach().numpy()\n",
    "\n",
    "        xrange = np.linspace(mean[0] - amp, mean[0] + amp, num=100)\n",
    "        yrange = np.linspace(mean[1] - amp, mean[1] + amp, num=100)\n",
    "        xbatch, ybatch = np.meshgrid(xrange, yrange)\n",
    "        assert xbatch.shape == ybatch.shape == (100, 100)\n",
    "\n",
    "        init_states = np.stack([xbatch, ybatch], axis=-1).reshape((-1, 2))\n",
    "        init_states = torch.from_numpy(init_states).float().refine_names(\"B\", \"R\")\n",
    "        assert init_states.shape == (10000, 2), init_states.shape\n",
    "\n",
    "        init_values = self(init_states).detach().numpy()\n",
    "        assert init_values.shape == (10000,), init_values.shape\n",
    "\n",
    "        init_values = init_values.reshape(xbatch.shape)\n",
    "        ax.plot_surface(xbatch, ybatch, init_values, cmap=cm.coolwarm)\n",
    "\n",
    "        ax.set_xlabel(\"x1\")\n",
    "        ax.set_ylabel(\"x2\")\n",
    "        ax.set_zlabel(\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact methods\n",
    "---\n",
    "## LQG control\n",
    "\n",
    "<img src=\"images/LQG - Control.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_solution(policy, qval, vval):\n",
    "    K, k = policy\n",
    "    Q, q, qc = qval\n",
    "    V, v, vc = vval\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    Policy:\n",
    "        K: {K.shape}, {K.names}\n",
    "        k: {k.shape}, {k.names}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    Q-value:\n",
    "        Q: {Q.shape}, {Q.names}\n",
    "        q: {q.shape}, {q.names}\n",
    "        const: {qc.shape}, {qc.names}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    V-value:\n",
    "        V: {V.shape}, {V.names}\n",
    "        V: {v.shape}, {v.names}\n",
    "        const: {vc.shape}, {vc.names}\n",
    "    \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.n_state = 2\n",
    "generator.n_ctrl = 2\n",
    "dynamics, cost, init = generator(n_batch=None)\n",
    "lqg_control = lqr.NamedLQGControl(\n",
    "    generator.n_state, generator.n_ctrl, generator.horizon\n",
    ")\n",
    "pistar, qstar, vstar = lqg_control(dynamics, cost)\n",
    "print_solution(pistar, qstar, vstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vstar_fn = ValueFn(vstar)\n",
    "print(vstar_fn.V)\n",
    "print(vstar_fn.v)\n",
    "print(vstar_fn.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal value for best initial state\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{s}_{min} \n",
    "&= \\arg\\min_{\\mathbf{s}} V^\\star(\\mathbf{s}, 0) \\\\\n",
    "&= \\arg\\min_{\\mathbf{s}} \\mathbf{s}^\\intercal \\mathbf{V}_0^\\star \\mathbf{s} + {\\mathbf{v}_0^\\star}^\\intercal \\mathbf{s} + v_0^\\star \\\\\n",
    "&= -{\\mathbf{V}_0^\\star}^{-1} \\mathbf{v}_0^\\star \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum = vstar_fn.min()\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Best initial state: {minimum}\n",
    "    Best initial value: {vstar_fn(minimum)}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal expected initial state value\n",
    "$$\n",
    "\\mathbb{E}_{\\mathbf{s}\\sim\\rho} \\left[ V^{\\star}(\\mathbf{s}, 0) \\right]\n",
    "= \\text{Tr}(\\mathbf{V}_0\\mathbf{\\Sigma}_0) + \\mathbf{\\mu}_0^\\intercal \\mathbf{V}_0 \\mathbf{\\mu}_0 + \\mathbf{v}_0^\\intercal \\mathbf{\\mu}_0 + v_0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"\"\"\n",
    "    Mean: {init.mu}\n",
    "    Covariance: {init.sig}\n",
    "    Expected value: {vstar_fn.expected(init)}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal value for each initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[2 * 6.4, 2 * 4.8])\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "vstar_fn.plot_3d(ax, mean=init.mu)\n",
    "# plt.savefig(\"navigation2d_value.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vstar_fn.symeig())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LQG prediction (Policy Evaluation)\n",
    "\n",
    "<img src=\"images/LQG - Prediction.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqg_prediction = lqr.NamedLQGPrediction(\n",
    "    generator.n_state, generator.n_ctrl, generator.horizon\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbed optimal policies\n",
    "\n",
    "We generate sub-optimal policies by adding uniform noise to the optimal policy's parameters, i.e., \n",
    "$$\n",
    "    \\mathbf{K}_t = \\mathbf{K}_t^\\star + \\epsilon, \\qquad \\epsilon \\sim \\mathcal{U}(\\mathbf{0}, \\mathbf{0.5}) \\\\\n",
    "    \\mathbf{k}_t = \\mathbf{k}_t^\\star + \\epsilon, \\qquad \\epsilon \\sim \\mathcal{U}(\\mathbf{0}, \\mathbf{0.5})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_policy(policy, rng):\n",
    "    Knames, knames = map(lambda x: x.names, policy)\n",
    "    K, k = map(lambda x: x.numpy(), policy)\n",
    "    K = torch.from_numpy(K + rng.standard_normal(size=K.shape, dtype=K.dtype) * .5)\n",
    "    k = torch.from_numpy(k + rng.standard_normal(size=k.shape, dtype=k.dtype) * .5)\n",
    "    return (K.refine_names(*Knames), k.refine_names(*knames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = rand_policy(pistar, rng=generator._rng)\n",
    "\n",
    "_, vval = lqg_prediction(policy, dynamics, cost)\n",
    "vval_fn = ValueFn(vval)\n",
    "min_state = vval_fn.min()\n",
    "print(\n",
    "    f\"\"\"\n",
    "    V: {vval_fn.V}\n",
    "    v: {vval_fn.v}\n",
    "    c: {vval_fn.c}\n",
    "    \n",
    "    min state: {min_state}\n",
    "    min value: {vval_fn(min_state)}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[2 * 6.4, 4 * 4.8])\n",
    "ax = fig.add_subplot(1, 2, 1, projection=\"3d\")\n",
    "vval_fn.plot_3d(ax, mean=init.mu)\n",
    "ax.set_title(\"Perturbed\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection=\"3d\")\n",
    "vstar_fn.plot_3d(ax, mean=init.mu)\n",
    "ax.set_title(\"Optimal\")\n",
    "\n",
    "# plt.savefig(\"navigation2d_value.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Perturbed:\")\n",
    "print(vval_fn.symeig())\n",
    "print(\"Optimal:\")\n",
    "print(vstar_fn.symeig())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy learning via true value gradients\n",
    "\n",
    "LQG prediction can be seen as a function mapping policy parameters (with the dynamics kept constant) to value function coefficients:\n",
    "$$\n",
    "\\left( \\mathbf{Q}, \\mathbf{q}, q, \\mathbf{V}, \\mathbf{v}, v \\right) = \\text{LQGPrediction}(\\theta)\n",
    "$$\n",
    "\n",
    "Thus, we can write each coeficient as a function of policy parameters. For example, the value function for a policy $\\mu_\\theta$ would be:\n",
    "$$\n",
    "V^\\mu(\\mathbf{s}, t) = \\tfrac12 \\mathbf{s}^\\intercal \\mathbf{V}_t(\\theta) \\mathbf{s} + \\mathbf{v}_t(\\theta)^\\intercal \\mathbf{s} + v_t(\\theta)\n",
    "$$\n",
    "\n",
    "We can then express policy performance as a direct function of policy parameters:\n",
    "$$\n",
    "\\begin{align}\n",
    "J(\\theta) \n",
    "    &= \\mathbb{E}_{\\mathbf{s}\\sim\\rho} \\left[ \\tfrac12 \\mathbf{s}^\\intercal \\mathbf{V}_0(\\theta) \\mathbf{s} + \\mathbf{v}_0(\\theta)^\\intercal \\mathbf{s} + v_0(\\theta) \\right] \\\\\n",
    "    &= \\text{Tr}(\\mathbf{V}_0(\\theta)\\mathbf{\\Sigma}_0) + \\mathbf{\\mu}_0^\\intercal \\mathbf{V}_0(\\theta) \\mathbf{\\mu}_0 + \\mathbf{v}_0(\\theta)^\\intercal \\mathbf{\\mu}_0 + v_0(\\theta)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVLFLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dynamics: lqr.LinDynamics,\n",
    "        cost: lqr.QuadCost,\n",
    "        init: lqr.GaussInit,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        n_state = dynamics.F.size(\"R\")\n",
    "        n_ctrl = dynamics.F.size(\"C\") - n_state\n",
    "        horizon = dynamics.F.size(\"H\")\n",
    "        self.predict = lqr.NamedLQGPrediction(n_state, n_ctrl, horizon)\n",
    "        self.dynamics = dynamics\n",
    "        self.cost = cost\n",
    "        self.init = init\n",
    "\n",
    "    def forward(self, policy: lqr.Linear):\n",
    "        _, vval = self.predict(policy, self.dynamics, self.cost)\n",
    "        vval_fn = ValueFn(vval)\n",
    "        cost = vval_fn.expected(self.init)\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = TVLFLoss(dynamics, cost, init)\n",
    "loss = loss_fn(policy)\n",
    "print(\"Random policy loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, since the value function coefficients are differentiable functions of the policy parameters, we can optimize the latter for better performance via gradient ascent\n",
    "$$\n",
    "\\theta \\gets \\theta + \\alpha \\nabla_{\\theta} J(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvlp = TVLinearFeedback.from_existing(policy)\n",
    "optim = torch.optim.Adam(tvlp.parameters(), lr=1e-3)\n",
    "\n",
    "for i in range(1000):\n",
    "    # for i in range(1):\n",
    "    for p in tvlp.parameters():\n",
    "        p.grad = None\n",
    "    loss = loss_fn(tvlp.gains())\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if i % 100 == 0:\n",
    "        print(\"Loss:\", loss.item())\n",
    "print(\"Loss:\", loss_fn(tvlp.gains()).item())\n",
    "print(\"Best possible:\", vstar_fn.expected(loss_fn.init).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_vval = ValueFn(lqg_prediction(tvlp.gains(), dynamics, cost)[1])\n",
    "fig = plt.figure(figsize=[2 * 6.4, 4 * 4.8])\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1, projection=\"3d\")\n",
    "vstar_fn.plot_3d(ax, mean=init.mu)\n",
    "ax.set_title(\"Optimal\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection=\"3d\")\n",
    "learned_vval.plot_3d(ax, mean=init.mu)\n",
    "ax.set_title(\"Learned\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
